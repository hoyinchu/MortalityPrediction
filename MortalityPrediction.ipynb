{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEFORE YOU RUN THIS NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to read README and run the process_data.py script according to the instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Sklearn models to compare\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Custom utility script for easy model evaluation\n",
    "from model_util import eval_sklearn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0 # for reproducibility (so models can be trained the exact same way and train/test are split the exact same way)\n",
    "MAX_ITER = 10000 # for logistic regression convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computs the micro and macro f1, precision, recall of logistic regression and random forest model on the given data\n",
    "def eval_models(feature_matrix,target_col,random_seed=RANDOM_SEED):\n",
    "    print(\"Logistic Regression Performance:\")\n",
    "    lr_clf = LogisticRegression(random_state=RANDOM_SEED,max_iter=MAX_ITER,class_weight='balanced')\n",
    "    lr_clf_report = eval_sklearn_model(lr_clf,feature_matrix,target_col,random_seed)\n",
    "    print(lr_clf_report)\n",
    "    print()\n",
    "    print(\"Random Forest Performance:\")\n",
    "    rf_clf = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "    rf_clf_report = eval_sklearn_model(rf_clf,feature_matrix,target_col,random_seed)\n",
    "    print(rf_clf_report)\n",
    "    \n",
    "    return lr_clf_report,rf_clf_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract baseline (demographic) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv(\"processed_data/baseline_features.csv\")\n",
    "baseline_feature_column_names = [col for col in baseline_df.columns if not (col == \"SUBJECT_ID\" or col == \"DIAGNOSIS\" or col == \"DIED\")]\n",
    "baseline_target_column_name = \"DIED\"\n",
    "baseline_feature_matrix = baseline_df[baseline_feature_column_names].to_numpy()\n",
    "baseline_target_col = baseline_df[baseline_target_column_name].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0 (Dummy Classifiers):  Always predict 1 or always predict 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first construct two dummy models that always predicts either 1 or 0 so we have something to compare to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hoyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hoyin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_0 = DummyClassifier(strategy='constant',constant=0,random_state=RANDOM_SEED)\n",
    "dummy_clf_1 = DummyClassifier(strategy='constant',constant=1,random_state=RANDOM_SEED)\n",
    "dummy_0_report = eval_sklearn_model(dummy_clf_0,baseline_feature_matrix,baseline_target_col,random_state=RANDOM_SEED)\n",
    "dummy_1_report = eval_sklearn_model(dummy_clf_1,baseline_feature_matrix,baseline_target_col,random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we may expect, due to the highly unbalanced nature of the dataset the dummy model has very good micro-averaged metrics (since it's only predicting the majority class) but poor macro-averaged metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifer (Always Predict 0) Performance: \n",
      "{'binary': {'f1': 0.0, 'precision': 0.0, 'recall': 0.0, 'AUPRC': 0.1477243507328362, 'AUROC': 0.5}, 'micro': {'f1': 0.8522756492671638, 'precision': 0.8522756492671638, 'recall': 0.8522756492671638, 'AUPRC': 0.1477243507328362, 'AUROC': 0.5}, 'macro': {'f1': 0.4601235510515722, 'precision': 0.4261378246335819, 'recall': 0.5, 'AUPRC': 0.1477243507328362, 'AUROC': 0.5}}\n",
      "\n",
      "Dummy Classifer (Always Predict 1) Performance: \n",
      "{'binary': {'f1': 0.25742130614988235, 'precision': 0.1477243507328362, 'recall': 1.0, 'AUPRC': 0.1477243507328362, 'AUROC': 0.5}, 'micro': {'f1': 0.1477243507328362, 'precision': 0.1477243507328362, 'recall': 0.1477243507328362, 'AUPRC': 0.1477243507328362, 'AUROC': 0.5}, 'macro': {'f1': 0.12871065307494117, 'precision': 0.0738621753664181, 'recall': 0.5, 'AUPRC': 0.1477243507328362, 'AUROC': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dummy Classifer (Always Predict 0) Performance: \")\n",
    "print(dummy_0_report)\n",
    "print()\n",
    "print(\"Dummy Classifer (Always Predict 1) Performance: \")\n",
    "print(dummy_1_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Logistic Regression (LR) and Random Forest (RF) using Demographic Info (baseline faetures) Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the performance of logistic regression (LR) and random forest (RF) on mortality prediction using only demographic feature. While neither model outperform the dummy model on micro-averaged metrics, we can see there are still signal in the data as both model received > 0.6 area under the ROC curve. From this experiment it seems LR is a better model than RF as it outperforms it in macro metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "{'binary': {'f1': 0.317582640438045, 'precision': 0.20703331570597566, 'recall': 0.6814621409921671, 'AUPRC': 0.23256219216327212, 'AUROC': 0.6641100547072685}, 'micro': {'f1': 0.567369503728465, 'precision': 0.567369503728465, 'recall': 0.567369503728465, 'AUPRC': 0.23256219216327212, 'AUROC': 0.6641100547072685}, 'macro': {'f1': 0.500438379042552, 'precision': 0.5577208620571921, 'recall': 0.6145280232793088, 'AUPRC': 0.23256219216327212, 'AUROC': 0.6641100547072685}}\n",
      "\n",
      "Random Forest Performance:\n",
      "{'binary': {'f1': 0.025256511444356748, 'precision': 0.13559322033898305, 'recall': 0.01392515230635335, 'AUPRC': 0.19790689062574157, 'AUROC': 0.6255298703996116}, 'micro': {'f1': 0.8412188223193623, 'precision': 0.8412188223193623, 'recall': 0.8412188223193623, 'AUPRC': 0.19790689062574157, 'AUROC': 0.6255298703996116}, 'macro': {'f1': 0.46941319518610164, 'precision': 0.493840996592468, 'recall': 0.49926910805844144, 'AUPRC': 0.19790689062574157, 'AUROC': 0.6255298703996116}}\n"
     ]
    }
   ],
   "source": [
    "baseline_lr_report, baseline_rf_report = eval_models(baseline_feature_matrix,baseline_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: LR and RF using diagnosis text embedding from DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will examine if the text embeddings obtained from applying DistilBERT to each patient's diagnosis text data contains any signals. Notice there is no leakage here since no training was done when the embeddings were produced therefore it is safe to produce the text embedding for train and test data at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_bert_text_embedding_df = pd.read_csv(\"processed_data/distil_bert_text_embedding.csv\")\n",
    "distil_bert_feature_column_names = [col for col in distil_bert_text_embedding_df.columns if not (col == \"SUBJECT_ID\" or col == \"DIED\")]\n",
    "distil_bert_target_column_name = \"DIED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_bert_feature_matrix = distil_bert_text_embedding_df[distil_bert_feature_column_names].to_numpy()\n",
    "distil_bert_target_col = distil_bert_text_embedding_df[distil_bert_target_column_name].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a significant performance boost when compared to using just baseline features which suggest that there are more useful information contained in the diagnosis text that are relevant to a patient's chance of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "{'binary': {'f1': 0.3610261237938338, 'precision': 0.24741935483870967, 'recall': 0.6675369886858138, 'AUPRC': 0.29732463283473315, 'AUROC': 0.7192813022821763}, 'micro': {'f1': 0.650938544613011, 'precision': 0.650938544613011, 'recall': 0.650938544613011, 'AUPRC': 0.29732463283473315, 'AUROC': 0.7192813022821763}, 'macro': {'f1': 0.5604546909762482, 'precision': 0.5828802631397482, 'recall': 0.6577992682152858, 'AUPRC': 0.29732463283473315, 'AUROC': 0.7192813022821763}}\n",
      "\n",
      "Random Forest Performance:\n",
      "{'binary': {'f1': 0.0846805234795997, 'precision': 0.36666666666666664, 'recall': 0.047867711053089644, 'AUPRC': 0.27362694699480156, 'AUROC': 0.6979210607819296}, 'micro': {'f1': 0.847132939058884, 'precision': 0.847132939058884, 'recall': 0.847132939058884, 'AUPRC': 0.27362694699480156, 'AUROC': 0.6979210607819296}, 'macro': {'f1': 0.500641447122419, 'precision': 0.6116238419856669, 'recall': 0.5167683705363503, 'AUPRC': 0.27362694699480156, 'AUROC': 0.6979210607819296}}\n"
     ]
    }
   ],
   "source": [
    "distil_bert_lr_report, distil_bert_rf_report = eval_models(distil_bert_feature_matrix,distil_bert_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: LR and RF using diagnosis text embedding from BlueBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BlueBERT is a BERT-based transformer fine-tuned using PubMed and other biomedical text data. We will examine if text embeddings produced by such domain adapted transformer will give LR and RF better performance than using text embeddings produced by the general purpose DistilBERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_bert_text_embedding_df = pd.read_csv(\"processed_data/blue_bert_text_embedding.csv\")\n",
    "blue_bert_feature_column_names = [col for col in blue_bert_text_embedding_df.columns if not (col == \"SUBJECT_ID\" or col == \"DIED\")]\n",
    "blue_bert_target_column_name = \"DIED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_bert_feature_matrix = blue_bert_text_embedding_df[blue_bert_feature_column_names].to_numpy()\n",
    "blue_bert_target_col = blue_bert_text_embedding_df[blue_bert_target_column_name].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar but not necessarily better performance when compared to using text embeddings produced by DistilBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "{'binary': {'f1': 0.36212086131048854, 'precision': 0.2466876971608833, 'recall': 0.68059181897302, 'AUPRC': 0.29253613124268774, 'AUROC': 0.7184465598779317}, 'micro': {'f1': 0.6457958344047313, 'precision': 0.6457958344047313, 'recall': 0.6457958344047313, 'AUPRC': 0.29253613124268774, 'AUROC': 0.7184465598779317}, 'macro': {'f1': 0.5584743311624971, 'precision': 0.5835217999693305, 'recall': 0.6601782446803552, 'AUPRC': 0.29253613124268774, 'AUROC': 0.7184465598779317}}\n",
      "\n",
      "Random Forest Performance:\n",
      "{'binary': {'f1': 0.08314087759815242, 'precision': 0.36, 'recall': 0.04699738903394256, 'AUPRC': 0.2797361442788494, 'AUROC': 0.7055071992265438}, 'micro': {'f1': 0.8468758035484699, 'precision': 0.84687580354847, 'recall': 0.84687580354847, 'AUPRC': 0.2797361442788494, 'AUROC': 0.7055071992265438}, 'macro': {'f1': 0.49980148319831874, 'precision': 0.6082249606712113, 'recall': 0.5162577833689851, 'AUPRC': 0.2797361442788494, 'AUROC': 0.7055071992265438}}\n"
     ]
    }
   ],
   "source": [
    "blue_bert_lr_report, blue_bert_rf_report = eval_models(blue_bert_feature_matrix,blue_bert_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: LR and RF using features from baseline + DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we combine the baseline features and the text embeddings to see if this would lead to increased performance or if the text embedding features overshadow the performance of the baseline features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distil_bert_df = pd.merge(baseline_df,distil_bert_text_embedding_df,how='inner',on=\"SUBJECT_ID\")\n",
    "baseline_distil_bert_feature_column_names = [col for col in baseline_distil_bert_df.columns if not (col == \"SUBJECT_ID\" or col == \"DIAGNOSIS\" or \"DIED\" in col)]\n",
    "baseline_distil_bert_target_column_name = \"DIED_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_distil_feature_matrix = baseline_distil_bert_df[baseline_distil_bert_feature_column_names].to_numpy()\n",
    "baseline_distil_target_col = baseline_distil_bert_df[baseline_distil_bert_target_column_name].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe an improvement over both using the baseline features alone and using the text embeddings alone. This suggest that the text data complements the baseline features to a certain degree. We also note that this improvement is only observed in LR but not RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "{'binary': {'f1': 0.3889573576534385, 'precision': 0.2713204951856946, 'recall': 0.6866840731070496, 'AUPRC': 0.32890150128693285, 'AUROC': 0.7487755557804993}, 'micro': {'f1': 0.6812805348418617, 'precision': 0.6812805348418617, 'recall': 0.6812805348418617, 'AUPRC': 0.32890150128693285, 'AUROC': 0.7487755557804993}, 'macro': {'f1': 0.5866866969152487, 'precision': 0.598699261966564, 'recall': 0.6835140081932894, 'AUPRC': 0.32890150128693285, 'AUROC': 0.7487755557804993}}\n",
      "\n",
      "Random Forest Performance:\n",
      "{'binary': {'f1': 0.18084473527662104, 'precision': 0.2857142857142857, 'recall': 0.13228894691035684, 'AUPRC': 0.2501866384085179, 'AUROC': 0.6755888787314122}, 'micro': {'f1': 0.8229622010799691, 'precision': 0.8229622010799691, 'recall': 0.8229622010799691, 'AUPRC': 0.2501866384085179, 'AUROC': 0.6755888787314122}, 'macro': {'f1': 0.5408007460166889, 'precision': 0.574060565435117, 'recall': 0.5374825334944, 'AUPRC': 0.2501866384085179, 'AUROC': 0.6755888787314122}}\n"
     ]
    }
   ],
   "source": [
    "baseline_distil_lr_report, baseline_distil_rf_report = eval_models(baseline_distil_feature_matrix,baseline_distil_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: LR and RF using features from baseline + BlueBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a similar experiment as above except using BlueBERT's text embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_blue_bert_df = pd.merge(baseline_df,blue_bert_text_embedding_df,how='inner',on=\"SUBJECT_ID\")\n",
    "baseline_blue_bert_feature_column_names = [col for col in baseline_blue_bert_df.columns if not (col == \"SUBJECT_ID\" or col == \"DIAGNOSIS\" or \"DIED\" in col)]\n",
    "baseline_blue_bert_target_column_name = \"DIED_x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_blue_feature_matrix = baseline_blue_bert_df[baseline_blue_bert_feature_column_names].to_numpy()\n",
    "baseline_blue_target_col = baseline_blue_bert_df[baseline_blue_bert_target_column_name].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both had very similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "{'binary': {'f1': 0.3889573576534385, 'precision': 0.2713204951856946, 'recall': 0.6866840731070496, 'AUPRC': 0.3201713445958627, 'AUROC': 0.7487017051038104}, 'micro': {'f1': 0.6812805348418617, 'precision': 0.6812805348418617, 'recall': 0.6812805348418617, 'AUPRC': 0.3201713445958627, 'AUROC': 0.7487017051038104}, 'macro': {'f1': 0.5866866969152487, 'precision': 0.598699261966564, 'recall': 0.6835140081932894, 'AUPRC': 0.3201713445958627, 'AUROC': 0.7487017051038104}}\n",
      "\n",
      "Random Forest Performance:\n",
      "{'binary': {'f1': 0.17671641791044776, 'precision': 0.2813688212927757, 'recall': 0.1288076588337685, 'AUPRC': 0.2514841805225723, 'AUROC': 0.6785698202678029}, 'micro': {'f1': 0.8227050655695551, 'precision': 0.8227050655695551, 'recall': 0.8227050655695551, 'AUPRC': 0.2514841805225723, 'AUROC': 0.6785698202678029}, 'macro': {'f1': 0.5386859951377756, 'precision': 0.5716689666309438, 'recall': 0.5358927417716889, 'AUPRC': 0.2514841805225723, 'AUROC': 0.6785698202678029}}\n"
     ]
    }
   ],
   "source": [
    "baseline_blue_lr_report, baseline_blue_rf_report = eval_models(baseline_blue_feature_matrix,baseline_blue_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Performance Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a helper function that groups all these scores together in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_reports_to_df(model_name_list,report_list):\n",
    "    assert len(report_list) > 0 and len(model_name_list) == len(report_list)\n",
    "    metric_names = [\"model\"]\n",
    "    metric_names += [f\"{key}_{metric}\" for key in report_list[0] for metric in report_list[0][key]]\n",
    "    rows = []\n",
    "    for idx,report in enumerate(report_list):\n",
    "        row = [model_name_list[idx]]\n",
    "        nums = [report[key][metric] for key in report for metric in report[key]]\n",
    "        row += nums\n",
    "        rows.append(row)\n",
    "    to_return_df = pd.DataFrame(columns=metric_names,data=rows)\n",
    "    return to_return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_reports = [dummy_0_report,dummy_1_report]\n",
    "dummy_model_names = [\"Dummy (Always Predict 0)\", \"Dummy (Always Predict 1)\"]\n",
    "dummy_report_df = convert_reports_to_df(dummy_model_names,dummy_reports)\n",
    "\n",
    "lr_reports = [baseline_lr_report,distil_bert_lr_report,blue_bert_lr_report,baseline_distil_lr_report,baseline_blue_lr_report]\n",
    "lr_model_names = [\"LR + Baseline\",\"LR + DistilBERT\", \"LR + BlueBERT\", \"LR + Baseline + DistilBERT\", \"LR + Baseline + BlueBERT\"]\n",
    "lr_report_df = convert_reports_to_df(lr_model_names,lr_reports)\n",
    "\n",
    "rf_reports = [baseline_rf_report,distil_bert_rf_report,blue_bert_rf_report,baseline_distil_rf_report,baseline_blue_rf_report]\n",
    "rf_model_names = [\"RF + Baseline\",\"RF + DistilBERT\", \"RF + BlueBERT\", \"RF + Baseline + DistilBERT\", \"RF + Baseline + BlueBERT\"]\n",
    "rf_report_df = convert_reports_to_df(rf_model_names,rf_reports)\n",
    "\n",
    "final_report_df = pd.concat([dummy_report_df,lr_report_df,rf_report_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>binary_f1</th>\n",
       "      <th>binary_precision</th>\n",
       "      <th>binary_recall</th>\n",
       "      <th>binary_AUPRC</th>\n",
       "      <th>binary_AUROC</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_AUPRC</th>\n",
       "      <th>micro_AUROC</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_AUPRC</th>\n",
       "      <th>macro_AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy (Always Predict 0)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.852276</td>\n",
       "      <td>0.852276</td>\n",
       "      <td>0.852276</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.460124</td>\n",
       "      <td>0.426138</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dummy (Always Predict 1)</td>\n",
       "      <td>0.257421</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.128711</td>\n",
       "      <td>0.073862</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147724</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR + Baseline</td>\n",
       "      <td>0.317583</td>\n",
       "      <td>0.207033</td>\n",
       "      <td>0.681462</td>\n",
       "      <td>0.232562</td>\n",
       "      <td>0.664110</td>\n",
       "      <td>0.567370</td>\n",
       "      <td>0.567370</td>\n",
       "      <td>0.567370</td>\n",
       "      <td>0.232562</td>\n",
       "      <td>0.664110</td>\n",
       "      <td>0.500438</td>\n",
       "      <td>0.557721</td>\n",
       "      <td>0.614528</td>\n",
       "      <td>0.232562</td>\n",
       "      <td>0.664110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR + DistilBERT</td>\n",
       "      <td>0.361026</td>\n",
       "      <td>0.247419</td>\n",
       "      <td>0.667537</td>\n",
       "      <td>0.297325</td>\n",
       "      <td>0.719281</td>\n",
       "      <td>0.650939</td>\n",
       "      <td>0.650939</td>\n",
       "      <td>0.650939</td>\n",
       "      <td>0.297325</td>\n",
       "      <td>0.719281</td>\n",
       "      <td>0.560455</td>\n",
       "      <td>0.582880</td>\n",
       "      <td>0.657799</td>\n",
       "      <td>0.297325</td>\n",
       "      <td>0.719281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR + BlueBERT</td>\n",
       "      <td>0.362121</td>\n",
       "      <td>0.246688</td>\n",
       "      <td>0.680592</td>\n",
       "      <td>0.292536</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.645796</td>\n",
       "      <td>0.645796</td>\n",
       "      <td>0.645796</td>\n",
       "      <td>0.292536</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.558474</td>\n",
       "      <td>0.583522</td>\n",
       "      <td>0.660178</td>\n",
       "      <td>0.292536</td>\n",
       "      <td>0.718447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR + Baseline + DistilBERT</td>\n",
       "      <td>0.388957</td>\n",
       "      <td>0.271320</td>\n",
       "      <td>0.686684</td>\n",
       "      <td>0.328902</td>\n",
       "      <td>0.748776</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.328902</td>\n",
       "      <td>0.748776</td>\n",
       "      <td>0.586687</td>\n",
       "      <td>0.598699</td>\n",
       "      <td>0.683514</td>\n",
       "      <td>0.328902</td>\n",
       "      <td>0.748776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR + Baseline + BlueBERT</td>\n",
       "      <td>0.388957</td>\n",
       "      <td>0.271320</td>\n",
       "      <td>0.686684</td>\n",
       "      <td>0.320171</td>\n",
       "      <td>0.748702</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.320171</td>\n",
       "      <td>0.748702</td>\n",
       "      <td>0.586687</td>\n",
       "      <td>0.598699</td>\n",
       "      <td>0.683514</td>\n",
       "      <td>0.320171</td>\n",
       "      <td>0.748702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF + Baseline</td>\n",
       "      <td>0.025257</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.197907</td>\n",
       "      <td>0.625530</td>\n",
       "      <td>0.841219</td>\n",
       "      <td>0.841219</td>\n",
       "      <td>0.841219</td>\n",
       "      <td>0.197907</td>\n",
       "      <td>0.625530</td>\n",
       "      <td>0.469413</td>\n",
       "      <td>0.493841</td>\n",
       "      <td>0.499269</td>\n",
       "      <td>0.197907</td>\n",
       "      <td>0.625530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF + DistilBERT</td>\n",
       "      <td>0.084681</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.047868</td>\n",
       "      <td>0.273627</td>\n",
       "      <td>0.697921</td>\n",
       "      <td>0.847133</td>\n",
       "      <td>0.847133</td>\n",
       "      <td>0.847133</td>\n",
       "      <td>0.273627</td>\n",
       "      <td>0.697921</td>\n",
       "      <td>0.500641</td>\n",
       "      <td>0.611624</td>\n",
       "      <td>0.516768</td>\n",
       "      <td>0.273627</td>\n",
       "      <td>0.697921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF + BlueBERT</td>\n",
       "      <td>0.083141</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.279736</td>\n",
       "      <td>0.705507</td>\n",
       "      <td>0.846876</td>\n",
       "      <td>0.846876</td>\n",
       "      <td>0.846876</td>\n",
       "      <td>0.279736</td>\n",
       "      <td>0.705507</td>\n",
       "      <td>0.499801</td>\n",
       "      <td>0.608225</td>\n",
       "      <td>0.516258</td>\n",
       "      <td>0.279736</td>\n",
       "      <td>0.705507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF + Baseline + DistilBERT</td>\n",
       "      <td>0.180845</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.132289</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>0.675589</td>\n",
       "      <td>0.822962</td>\n",
       "      <td>0.822962</td>\n",
       "      <td>0.822962</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>0.675589</td>\n",
       "      <td>0.540801</td>\n",
       "      <td>0.574061</td>\n",
       "      <td>0.537483</td>\n",
       "      <td>0.250187</td>\n",
       "      <td>0.675589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF + Baseline + BlueBERT</td>\n",
       "      <td>0.176716</td>\n",
       "      <td>0.281369</td>\n",
       "      <td>0.128808</td>\n",
       "      <td>0.251484</td>\n",
       "      <td>0.678570</td>\n",
       "      <td>0.822705</td>\n",
       "      <td>0.822705</td>\n",
       "      <td>0.822705</td>\n",
       "      <td>0.251484</td>\n",
       "      <td>0.678570</td>\n",
       "      <td>0.538686</td>\n",
       "      <td>0.571669</td>\n",
       "      <td>0.535893</td>\n",
       "      <td>0.251484</td>\n",
       "      <td>0.678570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  binary_f1  binary_precision  binary_recall  \\\n",
       "0     Dummy (Always Predict 0)   0.000000          0.000000       0.000000   \n",
       "1     Dummy (Always Predict 1)   0.257421          0.147724       1.000000   \n",
       "2                LR + Baseline   0.317583          0.207033       0.681462   \n",
       "3              LR + DistilBERT   0.361026          0.247419       0.667537   \n",
       "4                LR + BlueBERT   0.362121          0.246688       0.680592   \n",
       "5   LR + Baseline + DistilBERT   0.388957          0.271320       0.686684   \n",
       "6     LR + Baseline + BlueBERT   0.388957          0.271320       0.686684   \n",
       "7                RF + Baseline   0.025257          0.135593       0.013925   \n",
       "8              RF + DistilBERT   0.084681          0.366667       0.047868   \n",
       "9                RF + BlueBERT   0.083141          0.360000       0.046997   \n",
       "10  RF + Baseline + DistilBERT   0.180845          0.285714       0.132289   \n",
       "11    RF + Baseline + BlueBERT   0.176716          0.281369       0.128808   \n",
       "\n",
       "    binary_AUPRC  binary_AUROC  micro_f1  micro_precision  micro_recall  \\\n",
       "0       0.147724      0.500000  0.852276         0.852276      0.852276   \n",
       "1       0.147724      0.500000  0.147724         0.147724      0.147724   \n",
       "2       0.232562      0.664110  0.567370         0.567370      0.567370   \n",
       "3       0.297325      0.719281  0.650939         0.650939      0.650939   \n",
       "4       0.292536      0.718447  0.645796         0.645796      0.645796   \n",
       "5       0.328902      0.748776  0.681281         0.681281      0.681281   \n",
       "6       0.320171      0.748702  0.681281         0.681281      0.681281   \n",
       "7       0.197907      0.625530  0.841219         0.841219      0.841219   \n",
       "8       0.273627      0.697921  0.847133         0.847133      0.847133   \n",
       "9       0.279736      0.705507  0.846876         0.846876      0.846876   \n",
       "10      0.250187      0.675589  0.822962         0.822962      0.822962   \n",
       "11      0.251484      0.678570  0.822705         0.822705      0.822705   \n",
       "\n",
       "    micro_AUPRC  micro_AUROC  macro_f1  macro_precision  macro_recall  \\\n",
       "0      0.147724     0.500000  0.460124         0.426138      0.500000   \n",
       "1      0.147724     0.500000  0.128711         0.073862      0.500000   \n",
       "2      0.232562     0.664110  0.500438         0.557721      0.614528   \n",
       "3      0.297325     0.719281  0.560455         0.582880      0.657799   \n",
       "4      0.292536     0.718447  0.558474         0.583522      0.660178   \n",
       "5      0.328902     0.748776  0.586687         0.598699      0.683514   \n",
       "6      0.320171     0.748702  0.586687         0.598699      0.683514   \n",
       "7      0.197907     0.625530  0.469413         0.493841      0.499269   \n",
       "8      0.273627     0.697921  0.500641         0.611624      0.516768   \n",
       "9      0.279736     0.705507  0.499801         0.608225      0.516258   \n",
       "10     0.250187     0.675589  0.540801         0.574061      0.537483   \n",
       "11     0.251484     0.678570  0.538686         0.571669      0.535893   \n",
       "\n",
       "    macro_AUPRC  macro_AUROC  \n",
       "0      0.147724     0.500000  \n",
       "1      0.147724     0.500000  \n",
       "2      0.232562     0.664110  \n",
       "3      0.297325     0.719281  \n",
       "4      0.292536     0.718447  \n",
       "5      0.328902     0.748776  \n",
       "6      0.320171     0.748702  \n",
       "7      0.197907     0.625530  \n",
       "8      0.273627     0.697921  \n",
       "9      0.279736     0.705507  \n",
       "10     0.250187     0.675589  \n",
       "11     0.251484     0.678570  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report_df.to_csv('lr_rf_report_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bitdd6a2358527242ea897ba8dd6dc37158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
